{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- https://github.com/Samvid95/AlgoTradingRepoList\n",
    "\n",
    "- https://www.google.com/amp/s/blog.mlq.ai/deep-reinforcement-learning-for-trading-with-tensorflow-2-0/amp/\n",
    "\n",
    "\n",
    "Quant Radio Podcast Ideas:\n",
    "- Transformer model\n",
    "  - really good at long sequences of time series data\n",
    "  - Recency important - continuously retrain your model\n",
    "- The bitter lesson \n",
    "  - https://www.quantitativo.com/p/the-bitter-lesson?utm_source=substack&utm_medium=web&utm_content=embedded-post&triedRedirect=true\n",
    "  - Don't just throw everything at the model, LESS IS MORE, pick a method and train using that style (e.g. momentum)\n",
    "- Learning to Rank Stocks\n",
    "  - https://www.quantitativo.com/p/learning-to-rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Raw Data\n",
    "   import csv of High, Low, Open, Close, Volume for 5-10 stocks\n",
    "  - Remove stocks with share price <$5\n",
    "  - Remove stocks with volatility indicator >X\n",
    "\n",
    "# Model 1:\n",
    "  - Simple bulk model\n",
    "    - Leverage the Bitter Lesson\n",
    "    - Maximum data throughput\n",
    "    - minimal human intervention \n",
    "\n",
    "  #### Inputs/Pre-processing:\n",
    "    - 20 log daily returns\n",
    "    - 12 log monthly returns (t-13 -> t-2)\n",
    "    - 1 January flag\n",
    "    - Convert returns to cumulative returns and z-scores for cross-sectional normalization\n",
    "  \n",
    "  #### The Model:\n",
    "    - Stacked RBMs to form an autoencoder, pretrained layer-wise\n",
    "    - Compress input to a low-dim feature space\n",
    "    - Pass to feedforward Neural Network for classification\n",
    "    - grid search with hold-out validation\n",
    "    - Final Architecture:\n",
    "      - 33-40-4-50-2\n",
    "      - 33 inputs, compressed to 4, classified into 2 classes\n",
    "    - \n",
    "\n",
    "  #### Target/Classification\n",
    "    - Above monthly returns\n",
    "    - Below monthly Returns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Momentum Indicator Enriched Model \n",
    "  - apply Trading indicators\n",
    "    - Volatility indicator, SMA, EMA, MACD, etc\n",
    "    - Return single Enriched dataframe for regression\n",
    "- Same model as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Ranking Portfolio with LambdaMART\n",
    "https://www.quantitativo.com/p/learning-to-rank\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/tutorials/learning_to_rank.html\n",
    "\n",
    "#### Features\n",
    "  - Compute asset scores using past returns, volatility-normalized indicators and momentum signals\n",
    "  - Modular framework - can encorporate additional features beyond momentum\n",
    "  - 6 features are past returns (raw and normalised for different windows), 15 momentum based features (different windows)\n",
    "\n",
    "#### Score Ranking\n",
    "  - Apply LambdaMART to rank stocks based on future expected performance\n",
    "\n",
    "#### Security Selection\n",
    "  - Long the top decile and short the bottome decile based upon rankings\n",
    "  - Increasing to 40 quantiles rather than 10 improves results but increases volatility and drawdowns\n",
    "  - Sharpe ratio optimised at between 30-40 quantiles\n",
    "\n",
    "#### Volatility scaling\n",
    "  - Normalize position sizes based on *ex-ante monthly volatility*, targeting 15% annualized volatility\n",
    "\n",
    "#### Re-Training and Rebalancing\n",
    "  - Rebalance monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ret-m1', 'ret-m2', 'ret-m3', 'ret-m4', 'ret-m5', 'ret-m6', 'ret-m7',\n",
      "       'ret-m8', 'ret-m9', 'ret-m10', 'ret-m11', 'ret-m12', 'ret-d1', 'ret-d2',\n",
      "       'ret-d3', 'ret-d4', 'ret-d5', 'ret-d6', 'ret-d7', 'ret-d8', 'ret-d9',\n",
      "       'ret-d10', 'ret-d11', 'ret-d12', 'ret-d13', 'ret-d14', 'ret-d15',\n",
      "       'ret-d16', 'ret-d17', 'ret-d18', 'ret-d19', 'ret-d20', 'unadj_close',\n",
      "       'is_next_jan', 'next_month_ret'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def get_data(symbol):\n",
    "    # Get raw price data (adjusted and unadjusted closes)\n",
    "    raw_df = pd.read_csv(fr\"C:\\Users\\dougl\\Desktop\\Personal Projects\\Deep Learning Algorithm\\RAW DATA\\{symbol}\")\n",
    "\n",
    "    raw_df = raw_df.replace(0, np.nan)\n",
    "    raw_df = raw_df.ffill()         # Foward Fill values to patch any gaps in time series data\n",
    "    raw_df['Date'] = pd.to_datetime(raw_df['Date'], dayfirst=True)\n",
    "    raw_df.set_index('Date', inplace=True)  # Set datetime index here\n",
    "\n",
    "    return raw_df\n",
    "    \n",
    "raw_df = get_data(\"VAS.csv\")  # Example symbol, replace with actual file name\n",
    "\n",
    "def process_data(raw_df, symbol):\n",
    "    \"\"\"\n",
    "    Constructs a feature-rich DataFrame indexed by (date, symbol) for use in predictive models.\n",
    "    Calculates monthly cumulative returns (ret-m1 to ret-m12) based on end-of-month closes and daily cumulative returns (ret-d1 to ret-d20) over the last 20 trading days.\n",
    "    Includes the unadjusted close price, a binary flag is_next_jan indicating if the next month is January, and the forward return for the next month (next_month_ret).\n",
    "    Ensures no missing or infinite values and returns a clean, multi-indexed dataset ready for modeling.\n",
    "    \"\"\"\n",
    "    # Get end-of-month data: last trading day of each month\n",
    "    eom = raw_df.groupby(pd.Grouper(freq='M')).last()\n",
    "    eom['is_next_jan'] = (eom.index.month == 12).astype(int)\n",
    "    eom['next_month_ret'] = eom['Close'].shift(-1) / eom['Close'] - 1\n",
    "\n",
    "    # Compute monthly cumulative returns over the past 12 months (ret-m1 to ret-m12)\n",
    "    monthly = pd.DataFrame(index=eom.index)\n",
    "    for m in range(1, 13):\n",
    "        monthly[f'ret-m{m}'] = (eom['Close'] / eom['Close'].shift(m)) - 1\n",
    "    monthly = monthly.dropna()\n",
    "    monthly = monthly.astype(float)\n",
    "\n",
    "    # Compute daily cumulative returns over the past 20 trading days (ret-d1 to ret-d20)\n",
    "    daily = pd.DataFrame(index=raw_df.index)\n",
    "    for d in range(1, 21):\n",
    "        daily[f'ret-d{d}'] = (raw_df['Close'] / raw_df['Close'].shift(d)) - 1\n",
    "    daily = daily.dropna()\n",
    "    daily = daily.astype(float)\n",
    "\n",
    "    # Align daily to end-of-month dates (last 20 trading days up to each EOM)\n",
    "    # For each EOM date, get the last available daily row <= EOM date\n",
    "    daily_eom = daily.loc[daily.index.isin(eom.index)]\n",
    "    if len(daily_eom) < len(eom):\n",
    "        # If not all EOM dates are present in daily, reindex with forward fill\n",
    "        daily_eom = daily.reindex(eom.index, method='ffill')\n",
    "\n",
    "    # Merge monthly and daily features with EOM targets and metadata\n",
    "    df = monthly.join(daily_eom, how='inner') \\\n",
    "                .join(eom[['Close', 'is_next_jan', 'next_month_ret']], how='inner')\n",
    "    df = df.rename(columns={'Close': 'unadj_close'})\n",
    "\n",
    "    # Clean: drop rows with any missing or infinite values\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # Return None if no usable rows\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Create MultiIndex (date, symbol)\n",
    "    df.index = pd.MultiIndex.from_tuples([(d, symbol) for d in df.index], names=[\"date\", \"symbol\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "print(process_data(raw_df, \"VAS.csv\").columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now going to loop through each of our stocks using the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL.csv', 'ALQ.csv', 'ATOM.csv', 'BGL.csv', 'CAR.csv', 'CSL.csv', 'DMP.csv', 'DVP.csv', 'FMG.csv', 'FPH.csv', 'GOLD.csv', 'JHX.csv', 'MIN.csv', 'MQG.csv', 'NWS.csv', 'NXG.csv', 'PDN.csv', 'PME.csv', 'QAN.csv', 'REA.csv', 'RMD.csv', 'SGH.csv', 'STO.csv', 'TWE.csv', 'VAS.csv', 'WCN.csv', 'WDS.csv', 'WHC.csv']\n",
      "(2648, 35)\n",
      "File saved successfully.\n",
      "Index(['ret-m1', 'ret-m2', 'ret-m3', 'ret-m4', 'ret-m5', 'ret-m6', 'ret-m7',\n",
      "       'ret-m8', 'ret-m9', 'ret-m10', 'ret-m11', 'ret-m12', 'ret-d1', 'ret-d2',\n",
      "       'ret-d3', 'ret-d4', 'ret-d5', 'ret-d6', 'ret-d7', 'ret-d8', 'ret-d9',\n",
      "       'ret-d10', 'ret-d11', 'ret-d12', 'ret-d13', 'ret-d14', 'ret-d15',\n",
      "       'ret-d16', 'ret-d17', 'ret-d18', 'ret-d19', 'ret-d20', 'unadj_close',\n",
      "       'is_next_jan', 'next_month_ret'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\dougl\\\\Desktop\\\\Personal Projects\\\\Deep Learning Algorithm\\\\RAW DATA\\\\\"\n",
    "\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files)\n",
    "\n",
    "full_data = []\n",
    "\n",
    "for stock in csv_files:\n",
    "    # print(f\"Loading {stock}\")\n",
    "    stock_df = get_data(stock)\n",
    "    stock_df = process_data(stock_df, stock)\n",
    "    # If process_data returns None, skip this stock\n",
    "    if stock_df is not None:\n",
    "        full_data.append(stock_df)\n",
    "    # print(f\"{stock} Loaded\")\n",
    "    # print(\"------\")\n",
    "\n",
    "# Combine all stock DataFrames into one\n",
    "full_data = pd.concat(full_data, axis=0)\n",
    "\n",
    "print(full_data.shape)\n",
    "\n",
    "try:\n",
    "    full_data.to_csv('Full_Dataframe.csv', index=True)\n",
    "    print(\"File saved successfully.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to save 'Full_Dataframe.csv': {e}\")\n",
    "\n",
    "print(full_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "Before training the model, we'll apply several pre-processing steps to clean, standardize features, and define target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out low-priced stocks - this is a proxy to remove illiquid and noisy stocks. Could enhance this in the future to use the VIX and a $'s traded metric instead.\n",
    "\n",
    "Next apply **Cross-sectional z-score standardization** to all features (except last two columns) to standardize them (I prefer normalisation)\n",
    "\n",
    "Next target variable is assigned a 1 if the next months return is above the median return for that date, otherwise a 0. \n",
    "\n",
    "Preserve the last feature (`is_next_jan`) and the original forward return for later analysis. All components are then combined into the single DataFrame for model input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ret-m1', 'ret-m2', 'ret-m3', 'ret-m4', 'ret-m5', 'ret-m6', 'ret-m7',\n",
      "       'ret-m8', 'ret-m9', 'ret-m10', 'ret-m11', 'ret-m12', 'ret-d1', 'ret-d2',\n",
      "       'ret-d3', 'ret-d4', 'ret-d5', 'ret-d6', 'ret-d7', 'ret-d8', 'ret-d9',\n",
      "       'ret-d10', 'ret-d11', 'ret-d12', 'ret-d13', 'ret-d14', 'ret-d15',\n",
      "       'ret-d16', 'ret-d17', 'ret-d18', 'ret-d19', 'ret-d20', 'is_next_jan',\n",
      "       'target', 'next_month_ret'],\n",
      "      dtype='object')\n",
      "<bound method NDFrame.head of date        symbol \n",
      "2016-06-30  ALL.csv    0.814109\n",
      "2016-07-31  ALL.csv    0.818213\n",
      "2016-08-31  ALL.csv   -0.079368\n",
      "2016-09-30  ALL.csv   -0.021750\n",
      "2016-10-31  ALL.csv    1.040548\n",
      "                         ...   \n",
      "2024-12-31  WHC.csv    1.763361\n",
      "2025-01-31  WHC.csv   -0.173003\n",
      "2025-02-28  WHC.csv    0.474797\n",
      "2025-03-31  WHC.csv    0.069649\n",
      "2025-05-31  WHC.csv   -0.577266\n",
      "Name: ret-d1, Length: 2108, dtype: float64>\n",
      "<bound method NDFrame.tail of date        symbol \n",
      "2016-06-30  ALL.csv    0.814109\n",
      "2016-07-31  ALL.csv    0.818213\n",
      "2016-08-31  ALL.csv   -0.079368\n",
      "2016-09-30  ALL.csv   -0.021750\n",
      "2016-10-31  ALL.csv    1.040548\n",
      "                         ...   \n",
      "2024-12-31  WHC.csv    1.763361\n",
      "2025-01-31  WHC.csv   -0.173003\n",
      "2025-02-28  WHC.csv    0.474797\n",
      "2025-03-31  WHC.csv    0.069649\n",
      "2025-05-31  WHC.csv   -0.577266\n",
      "Name: ret-d1, Length: 2108, dtype: float64>\n"
     ]
    }
   ],
   "source": [
    "# Filter out penny stocks: keep only rows where unadjusted close is \n",
    "# greater than $5\n",
    "raw = full_data[full_data['unadj_close'] > 5]\n",
    "\n",
    "# Drop the unadjusted close column—it’s no longer needed\n",
    "raw = raw.drop(columns=['unadj_close'])\n",
    "\n",
    "# Standardize features (z-score) within each date (cross-sectionally)\n",
    "features_std = raw.iloc[:, :-2].groupby(level=0)\\\n",
    "    .transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Extract the raw (non-standardized) version of the last feature column (is_next_jan)\n",
    "feature_raw = raw.iloc[:, -2]\n",
    "\n",
    "# Binary target: 1 if next_month_ret is above the cross-sectional median \n",
    "# for that date, else 0\n",
    "target = raw.iloc[:, -1]\n",
    "target = (target > target.groupby(level=0).transform('median')).astype(int)\n",
    "target.name = 'target'\n",
    "\n",
    "# Preserve the original next_month_ret values for reference or evaluation\n",
    "next_month_ret = raw.iloc[:, -1]\n",
    "\n",
    "# Concatenate standardized features, raw feature, target, and \n",
    "# forward return into final dataset\n",
    "data = pd.concat([features_std, feature_raw, target, next_month_ret], axis=1)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "print(data[\"ret-d1\"].head)\n",
    "print(data[\"ret-d1\"].tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation splits\n",
    "To evaluate model performance over time, we implement a **rolling-window cross-validation** framework tailored for time series data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data, look_back_years, val_years, validation_first=False):\n",
    "    \"\"\"\n",
    "    Generator that yields rolling train/validation/test splits from a time-indexed DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A pandas DataFrame indexed by date (multi-index allowed, first level must be date)\n",
    "    - look_back_years: Total number of years in the rolling window (train + val)\n",
    "    - val_years: Number of years allocated to validation set\n",
    "    - validation_first: If True, use the order Val → Train → Test; else Train → Val → Test\n",
    "\n",
    "    Yields:\n",
    "    - train_data: training data for current rolling window\n",
    "    - val_data: validation data for current rolling window\n",
    "    - test_data: test data for current rolling window\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a DataFrame with unique dates from the input index. Takes both Stock and Date for index\n",
    "    dt = pd.DataFrame(index=data.index.get_level_values(0).unique())\n",
    "\n",
    "    # Assign each date a corresponding year; shift December forward to avoid lookahead bias\n",
    "    dt['year'] = dt.index\n",
    "    dt['year'] = dt['year'].apply(lambda x: x.year if x.month != 12 else x.year + 1)\n",
    "\n",
    "    # Establish boundaries for rolling window\n",
    "    current_start_year = dt['year'].iloc[0]  # first available year\n",
    "    max_year = dt['year'].max()              # last year available in data\n",
    "\n",
    "    print(f\"Start year: {current_start_year}, Max year: {max_year}\")\n",
    "\n",
    "    while True:\n",
    "        # Determine where to start train and val periods based on validation_first flag\n",
    "        if validation_first:\n",
    "            val_start_year = current_start_year\n",
    "            train_start_year = current_start_year + val_years\n",
    "        else:\n",
    "            train_start_year = current_start_year\n",
    "            val_start_year = current_start_year + (look_back_years - val_years)\n",
    "\n",
    "        test_year = current_start_year + look_back_years\n",
    "        print(test_year, max_year)\n",
    "\n",
    "        # Stop if we've run out of years to create a full test period\n",
    "        if test_year > max_year:\n",
    "            break\n",
    "\n",
    "        # Map year boundaries to actual dates in the original data\n",
    "        val_start = dt[dt['year'] == val_start_year].index.min()\n",
    "        train_start = dt[dt['year'] == train_start_year].index.min()\n",
    "        test_start = dt[dt['year'] == test_year].index.min()\n",
    "        test_end = dt[dt['year'] == test_year].index.max()\n",
    "\n",
    "        # Create masks for filtering the data based on date ranges\n",
    "        if validation_first:\n",
    "            # Validation → Training → Test\n",
    "            val_mask = (data.index.get_level_values(0) > val_start) & \\\n",
    "                       (data.index.get_level_values(0) <= train_start)\n",
    "            train_mask = (data.index.get_level_values(0) > train_start) & \\\n",
    "                         (data.index.get_level_values(0) <= test_start)\n",
    "        else:\n",
    "            # Training → Validation → Test (default)\n",
    "            train_mask = (data.index.get_level_values(0) > train_start) & \\\n",
    "                         (data.index.get_level_values(0) <= val_start)\n",
    "            val_mask = (data.index.get_level_values(0) > val_start) & \\\n",
    "                       (data.index.get_level_values(0) <= test_start)\n",
    "\n",
    "        # Define mask for the test set: follows val/train period\n",
    "        test_mask = (data.index.get_level_values(0) > test_start) & \\\n",
    "                    (data.index.get_level_values(0) <= test_end)\n",
    "\n",
    "        # Apply masks to extract subsets from data\n",
    "        train_data = data.loc[train_mask]\n",
    "        val_data = data.loc[val_mask]\n",
    "        test_data = data.loc[test_mask]\n",
    "\n",
    "        # Yield split data\n",
    "        yield train_data, val_data, test_data\n",
    "\n",
    "        # Advance rolling window by one year for next iteration\n",
    "        current_start_year += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates chronological train/validation/test splits by sliding a multi-year window forward one year at a time. for each iteration it defintes the training period, validation period and test year - ensuring no data leakage. This is an implimentation of the Cross-Validation split referenced earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start year: 2016, Max year: 2025\n",
      "2020 2025\n",
      "2021 2025\n",
      "2022 2025\n",
      "2023 2025\n",
      "2024 2025\n",
      "2025 2025\n",
      "2026 2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_start</th>\n",
       "      <th>val_end</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>training_sampes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_start    val_end train_start  train_end test_start   test_end  \\\n",
       "0 2016-07-31 2018-12-31  2019-01-31 2019-12-31 2020-01-31 2020-11-30   \n",
       "1 2017-01-31 2019-12-31  2020-01-31 2020-12-31 2021-01-31 2021-11-30   \n",
       "2 2018-01-31 2020-12-31  2021-01-31 2021-12-31 2022-01-31 2022-11-30   \n",
       "3 2019-01-31 2021-12-31  2022-01-31 2022-12-31 2023-01-31 2023-11-30   \n",
       "4 2020-01-31 2022-12-31  2023-01-31 2023-12-31 2024-01-31 2024-11-30   \n",
       "5 2021-01-31 2023-12-31  2024-01-31 2024-12-31 2025-01-31 2025-05-31   \n",
       "\n",
       "   training_sampes  \n",
       "0              527  \n",
       "1              658  \n",
       "2              665  \n",
       "3              665  \n",
       "4              675  \n",
       "5              720  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['val_start', 'val_end', 'train_start', 'train_end', \n",
    "                           'test_start', 'test_end', 'training_sampes'])\n",
    "for train_data, val_data, test_data in train_val_test_split(data, 4, 1):\n",
    "    df.loc[len(df)] = [\n",
    "        train_data.index.get_level_values(0).min(),\n",
    "        train_data.index.get_level_values(0).max(),\n",
    "        val_data.index.get_level_values(0).min(),\n",
    "        val_data.index.get_level_values(0).max(),\n",
    "        test_data.index.get_level_values(0).min(),\n",
    "        test_data.index.get_level_values(0).max(),\n",
    "        len(train_data)\n",
    "    ]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model: FFNN\n",
    "We'll use a simple FeedForwards Neural Network architecture to classify the pre-processed features into two classes, as specified in the paper.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp311-cp311-win_amd64.whl (216.1 MB)\n",
      "     ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.2/216.1 MB 5.6 MB/s eta 0:00:39\n",
      "     ---------------------------------------- 0.5/216.1 MB 6.3 MB/s eta 0:00:35\n",
      "     ---------------------------------------- 0.8/216.1 MB 6.7 MB/s eta 0:00:33\n",
      "     ---------------------------------------- 1.4/216.1 MB 7.4 MB/s eta 0:00:29\n",
      "     ---------------------------------------- 2.0/216.1 MB 9.1 MB/s eta 0:00:24\n",
      "     ---------------------------------------- 2.3/216.1 MB 9.1 MB/s eta 0:00:24\n",
      "      --------------------------------------- 3.0/216.1 MB 9.5 MB/s eta 0:00:23\n",
      "      -------------------------------------- 3.6/216.1 MB 10.0 MB/s eta 0:00:22\n",
      "      --------------------------------------- 3.9/216.1 MB 9.8 MB/s eta 0:00:22\n",
      "      -------------------------------------- 4.8/216.1 MB 10.6 MB/s eta 0:00:20\n",
      "      -------------------------------------- 5.3/216.1 MB 10.9 MB/s eta 0:00:20\n",
      "     - ------------------------------------- 6.2/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 6.7/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 6.7/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 6.7/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 6.7/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 8.3/216.1 MB 10.6 MB/s eta 0:00:20\n",
      "     - ------------------------------------- 9.3/216.1 MB 11.3 MB/s eta 0:00:19\n",
      "     - ------------------------------------ 10.0/216.1 MB 11.5 MB/s eta 0:00:18\n",
      "     - ------------------------------------ 10.6/216.1 MB 11.9 MB/s eta 0:00:18\n",
      "     - ------------------------------------ 10.9/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 11.6/216.1 MB 12.6 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 12.2/216.1 MB 12.4 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 12.9/216.1 MB 12.6 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 13.1/216.1 MB 12.6 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 13.6/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 13.6/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 14.2/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 14.2/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 16.4/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 16.9/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 17.0/216.1 MB 14.6 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 17.3/216.1 MB 14.2 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 18.1/216.1 MB 13.4 MB/s eta 0:00:15\n",
      "     --- ---------------------------------- 18.9/216.1 MB 12.6 MB/s eta 0:00:16\n",
      "     --- ---------------------------------- 19.6/216.1 MB 12.6 MB/s eta 0:00:16\n",
      "     --- ---------------------------------- 20.1/216.1 MB 12.4 MB/s eta 0:00:16\n",
      "     --- ---------------------------------- 20.3/216.1 MB 11.9 MB/s eta 0:00:17\n",
      "     --- ---------------------------------- 21.1/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     --- ---------------------------------- 21.7/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     --- ---------------------------------- 22.1/216.1 MB 12.1 MB/s eta 0:00:17\n",
      "     --- ---------------------------------- 22.7/216.1 MB 12.4 MB/s eta 0:00:16\n",
      "     ---- --------------------------------- 23.7/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 24.3/216.1 MB 13.4 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 24.9/216.1 MB 14.6 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 25.4/216.1 MB 13.9 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 26.1/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 26.1/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 27.3/216.1 MB 13.1 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 28.1/216.1 MB 13.4 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 28.3/216.1 MB 13.4 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 28.9/216.1 MB 13.4 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 29.7/216.1 MB 13.1 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 30.4/216.1 MB 13.9 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 30.5/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 31.4/216.1 MB 13.6 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 32.2/216.1 MB 14.2 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 33.0/216.1 MB 14.2 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 33.0/216.1 MB 14.2 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 33.5/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ------ ------------------------------- 34.4/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 34.4/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 34.5/216.1 MB 11.7 MB/s eta 0:00:16\n",
      "     ------ ------------------------------- 36.1/216.1 MB 12.8 MB/s eta 0:00:15\n",
      "     ------ ------------------------------- 37.0/216.1 MB 13.6 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 37.2/216.1 MB 13.6 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 38.2/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 38.8/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 39.1/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 39.6/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 40.6/216.1 MB 12.9 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 41.1/216.1 MB 13.4 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 41.4/216.1 MB 13.4 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 42.3/216.1 MB 13.1 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 42.9/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 43.4/216.1 MB 13.9 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 44.3/216.1 MB 13.6 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 45.1/216.1 MB 14.9 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 45.4/216.1 MB 14.6 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 45.7/216.1 MB 13.9 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 46.9/216.1 MB 13.6 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 47.4/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 47.8/216.1 MB 13.6 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 48.5/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 49.2/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 49.6/216.1 MB 13.6 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 50.2/216.1 MB 13.6 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 51.1/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     --------- ---------------------------- 51.9/216.1 MB 14.2 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 52.1/216.1 MB 13.9 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 52.9/216.1 MB 13.4 MB/s eta 0:00:13\n",
      "     --------- ---------------------------- 53.0/216.1 MB 13.1 MB/s eta 0:00:13\n",
      "     --------- ---------------------------- 53.0/216.1 MB 13.1 MB/s eta 0:00:13\n",
      "     --------- ---------------------------- 54.7/216.1 MB 13.6 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 54.7/216.1 MB 13.6 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 55.2/216.1 MB 12.6 MB/s eta 0:00:13\n",
      "     --------- ---------------------------- 56.1/216.1 MB 13.4 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 56.6/216.1 MB 12.8 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 57.8/216.1 MB 13.4 MB/s eta 0:00:12\n",
      "     ---------- --------------------------- 58.0/216.1 MB 13.6 MB/s eta 0:00:12\n",
      "     ---------- --------------------------- 58.2/216.1 MB 13.1 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 58.9/216.1 MB 12.8 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 58.9/216.1 MB 12.8 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 59.7/216.1 MB 11.7 MB/s eta 0:00:14\n",
      "     ---------- --------------------------- 60.8/216.1 MB 12.8 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 61.6/216.1 MB 12.4 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 61.7/216.1 MB 11.9 MB/s eta 0:00:13\n",
      "     ---------- --------------------------- 61.7/216.1 MB 11.9 MB/s eta 0:00:13\n",
      "     ----------- -------------------------- 62.9/216.1 MB 12.1 MB/s eta 0:00:13\n",
      "     ----------- -------------------------- 63.7/216.1 MB 13.6 MB/s eta 0:00:12\n",
      "     ----------- -------------------------- 64.2/216.1 MB 12.8 MB/s eta 0:00:12\n",
      "     ----------- -------------------------- 64.6/216.1 MB 12.6 MB/s eta 0:00:13\n",
      "     ----------- -------------------------- 65.1/216.1 MB 12.6 MB/s eta 0:00:13\n",
      "     ----------- -------------------------- 66.1/216.1 MB 12.8 MB/s eta 0:00:12\n",
      "     ----------- -------------------------- 66.6/216.1 MB 12.6 MB/s eta 0:00:12\n",
      "     ----------- -------------------------- 67.3/216.1 MB 13.1 MB/s eta 0:00:12\n",
      "     ----------- -------------------------- 67.9/216.1 MB 12.6 MB/s eta 0:00:12\n",
      "     ------------ ------------------------- 68.3/216.1 MB 12.6 MB/s eta 0:00:12\n",
      "     ------------ ------------------------- 69.1/216.1 MB 12.8 MB/s eta 0:00:12\n",
      "     ------------ ------------------------- 69.5/216.1 MB 14.2 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 70.3/216.1 MB 13.6 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 70.9/216.1 MB 12.8 MB/s eta 0:00:12\n",
      "     ------------ ------------------------- 71.5/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 72.0/216.1 MB 14.9 MB/s eta 0:00:10\n",
      "     ------------ ------------------------- 72.6/216.1 MB 13.9 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 72.6/216.1 MB 13.9 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 74.1/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 74.4/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 75.0/216.1 MB 13.6 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 75.2/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 75.2/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 77.1/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 77.5/216.1 MB 12.8 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 78.1/216.1 MB 12.8 MB/s eta 0:00:11\n",
      "     ------------- ------------------------ 78.4/216.1 MB 12.4 MB/s eta 0:00:12\n",
      "     ------------- ------------------------ 78.8/216.1 MB 13.4 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 80.0/216.1 MB 13.1 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 80.1/216.1 MB 12.8 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 81.0/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 81.6/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 82.0/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 82.0/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 82.0/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 82.7/216.1 MB 11.1 MB/s eta 0:00:13\n",
      "     -------------- ----------------------- 84.1/216.1 MB 11.9 MB/s eta 0:00:12\n",
      "     -------------- ----------------------- 84.8/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     -------------- ----------------------- 84.9/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 85.8/216.1 MB 13.1 MB/s eta 0:00:10\n",
      "     --------------- ---------------------- 86.3/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 86.7/216.1 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 87.7/216.1 MB 12.3 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 87.7/216.1 MB 12.3 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 88.8/216.1 MB 12.6 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 89.3/216.1 MB 12.8 MB/s eta 0:00:10\n",
      "     --------------- ---------------------- 89.9/216.1 MB 12.4 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 89.9/216.1 MB 12.4 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 90.4/216.1 MB 12.3 MB/s eta 0:00:11\n",
      "     ---------------- --------------------- 91.3/216.1 MB 12.6 MB/s eta 0:00:10\n",
      "     ---------------- --------------------- 92.4/216.1 MB 14.2 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 93.2/216.1 MB 14.6 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 93.6/216.1 MB 13.6 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 94.1/216.1 MB 12.8 MB/s eta 0:00:10\n",
      "     ---------------- --------------------- 94.9/216.1 MB 13.1 MB/s eta 0:00:10\n",
      "     ---------------- --------------------- 95.4/216.1 MB 13.9 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 96.0/216.1 MB 13.1 MB/s eta 0:00:10\n",
      "     ----------------- -------------------- 96.7/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 96.7/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 97.2/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 97.7/216.1 MB 12.4 MB/s eta 0:00:10\n",
      "     ----------------- -------------------- 99.0/216.1 MB 12.8 MB/s eta 0:00:10\n",
      "     ----------------- -------------------- 99.5/216.1 MB 13.6 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 100.4/216.1 MB 14.2 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 100.9/216.1 MB 14.2 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 100.9/216.1 MB 14.2 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 100.9/216.1 MB 14.2 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 102.6/216.1 MB 12.9 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 103.3/216.1 MB 12.8 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 104.0/216.1 MB 13.1 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 104.0/216.1 MB 12.4 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 105.0/216.1 MB 12.8 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 105.2/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 106.1/216.1 MB 12.9 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 106.9/216.1 MB 12.8 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 107.3/216.1 MB 13.1 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 107.7/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 108.3/216.1 MB 13.6 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 108.5/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 108.5/216.1 MB 13.4 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 110.4/216.1 MB 12.8 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 111.1/216.1 MB 12.8 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 111.6/216.1 MB 14.6 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 111.6/216.1 MB 14.6 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 112.7/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 113.3/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 113.9/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 114.3/216.1 MB 14.2 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 114.9/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 115.8/216.1 MB 13.6 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 116.4/216.1 MB 13.9 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 116.4/216.1 MB 13.9 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 117.6/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 117.6/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 118.6/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 118.9/216.1 MB 14.2 MB/s eta 0:00:07\n",
      "     -------------------- ---------------- 120.2/216.1 MB 13.9 MB/s eta 0:00:07\n",
      "     -------------------- ---------------- 120.5/216.1 MB 12.9 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 121.3/216.1 MB 13.1 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 121.6/216.1 MB 12.8 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 122.1/216.1 MB 13.4 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 122.4/216.1 MB 12.8 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 122.4/216.1 MB 12.8 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 123.3/216.1 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 123.3/216.1 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 124.1/216.1 MB 11.5 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 125.2/216.1 MB 12.1 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 125.8/216.1 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 126.1/216.1 MB 12.6 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 127.3/216.1 MB 12.6 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 127.4/216.1 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 127.4/216.1 MB 11.3 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 129.0/216.1 MB 12.8 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 129.2/216.1 MB 12.6 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 129.2/216.1 MB 12.6 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 129.7/216.1 MB 11.1 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 131.1/216.1 MB 12.1 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 131.5/216.1 MB 11.9 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 132.2/216.1 MB 12.1 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 132.2/216.1 MB 12.1 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 133.3/216.1 MB 13.4 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 133.3/216.1 MB 13.4 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 134.7/216.1 MB 13.1 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 135.2/216.1 MB 12.4 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 135.2/216.1 MB 12.4 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 135.6/216.1 MB 12.1 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 137.1/216.1 MB 12.6 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 137.2/216.1 MB 12.1 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 138.2/216.1 MB 13.1 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 138.8/216.1 MB 12.4 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 139.1/216.1 MB 12.9 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 140.0/216.1 MB 14.2 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 140.4/216.1 MB 13.9 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 141.3/216.1 MB 13.1 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 141.3/216.1 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 142.3/216.1 MB 12.9 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 142.8/216.1 MB 13.6 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 143.6/216.1 MB 13.9 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 144.2/216.1 MB 13.9 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 145.2/216.1 MB 13.9 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 145.5/216.1 MB 14.6 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 145.9/216.1 MB 14.6 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 146.4/216.1 MB 13.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 147.1/216.1 MB 12.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 147.8/216.1 MB 12.8 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 148.7/216.1 MB 13.6 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 149.1/216.1 MB 13.4 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 149.1/216.1 MB 13.4 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 149.1/216.1 MB 13.4 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 150.9/216.1 MB 13.6 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 151.4/216.1 MB 12.8 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 152.2/216.1 MB 13.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 152.9/216.1 MB 13.4 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 153.3/216.1 MB 13.4 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 153.3/216.1 MB 13.4 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 154.2/216.1 MB 12.6 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 154.2/216.1 MB 11.9 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 155.5/216.1 MB 12.8 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 156.5/216.1 MB 13.6 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 156.9/216.1 MB 13.9 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 157.6/216.1 MB 13.6 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 157.8/216.1 MB 13.4 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 158.8/216.1 MB 12.8 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 159.2/216.1 MB 12.8 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 159.6/216.1 MB 14.6 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 160.4/216.1 MB 13.6 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 161.1/216.1 MB 13.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 161.8/216.1 MB 13.4 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 161.9/216.1 MB 13.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 162.6/216.1 MB 13.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 162.6/216.1 MB 13.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 163.2/216.1 MB 11.9 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 164.6/216.1 MB 14.2 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 165.3/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 165.9/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 166.5/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 167.2/216.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 167.6/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 167.6/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 168.6/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 169.6/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 170.2/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 170.2/216.1 MB 13.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 171.1/216.1 MB 12.8 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 171.1/216.1 MB 12.8 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 171.7/216.1 MB 11.9 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 172.6/216.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 173.4/216.1 MB 13.9 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 174.4/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 174.4/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 175.6/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 175.6/216.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 176.6/216.1 MB 13.4 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 177.5/216.1 MB 13.4 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 177.9/216.1 MB 14.6 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 178.2/216.1 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 178.6/216.1 MB 12.8 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 179.8/216.1 MB 13.1 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 180.0/216.1 MB 12.8 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 180.9/216.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 181.4/216.1 MB 14.9 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 182.0/216.1 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 182.4/216.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 183.3/216.1 MB 13.1 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 183.9/216.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 184.5/216.1 MB 13.1 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 185.0/216.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 185.8/216.1 MB 13.1 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 186.2/216.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 186.6/216.1 MB 12.8 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 186.9/216.1 MB 13.4 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 186.9/216.1 MB 13.4 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 186.9/216.1 MB 13.4 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 189.1/216.1 MB 13.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 189.2/216.1 MB 13.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 189.9/216.1 MB 12.8 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 190.7/216.1 MB 13.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 191.0/216.1 MB 12.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 191.7/216.1 MB 12.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 192.4/216.1 MB 12.8 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 192.9/216.1 MB 13.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 193.6/216.1 MB 13.1 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 194.4/216.1 MB 13.1 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 194.6/216.1 MB 12.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 195.6/216.1 MB 12.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 196.1/216.1 MB 12.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 196.5/216.1 MB 13.1 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 197.5/216.1 MB 15.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 197.9/216.1 MB 14.9 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 198.4/216.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 198.7/216.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 199.7/216.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 200.0/216.1 MB 13.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 201.0/216.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 201.0/216.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 201.7/216.1 MB 12.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 202.6/216.1 MB 12.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 203.3/216.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 203.6/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 203.8/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 204.9/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 204.9/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 205.8/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 205.8/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 207.3/216.1 MB 12.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 207.9/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 208.2/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 208.2/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 209.7/216.1 MB 12.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 210.1/216.1 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  210.6/216.1 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  211.2/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  211.5/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  211.9/216.1 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  212.4/216.1 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  213.3/216.1 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  213.9/216.1 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  214.2/216.1 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  214.6/216.1 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  215.7/216.1 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  216.1/216.1 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 216.1/216.1 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dougl\\miniconda3\\envs\\env-stocktrade01\\lib\\site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.7/6.3 MB 14.2 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 1.2/6.3 MB 14.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.6/6.3 MB 12.9 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.1/6.3 MB 12.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.0/6.3 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.1/6.3 MB 12.4 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 3.7/6.3 MB 12.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.6/6.3 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.9/6.3 MB 12.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.8/6.3 MB 12.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.3/6.3 MB 12.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.3/6.3 MB 11.5 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 0.7/2.0 MB 21.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.5/2.0 MB 18.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 14.4 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 134.9/134.9 kB ? eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "     ---------------------------------------- 0.0/199.1 kB ? eta -:--:--\n",
      "     ------------------------------------- 199.1/199.1 kB 11.8 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------  532.5/536.2 kB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch.nn (from versions: none)\n",
      "ERROR: No matching distribution found for torch.nn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torch.nn\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(33, 40)\n",
    "        self.fc2 = nn.Linear(40, 4)\n",
    "        self.fc3 = nn.Linear(4, 50)\n",
    "        self.out = nn.Linear(50, 2)  # logits for 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.out(x)  # pass logits to CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.tail of 2021-03-31  ALL.csv   NaN\n",
      "2021-04-30  ALL.csv   NaN\n",
      "2021-05-31  ALL.csv   NaN\n",
      "2021-06-30  ALL.csv   NaN\n",
      "2021-08-31  ALL.csv   NaN\n",
      "                       ..\n",
      "2023-07-31  WHC.csv   NaN\n",
      "2023-08-31  WHC.csv   NaN\n",
      "2023-10-31  WHC.csv   NaN\n",
      "2023-11-30  WHC.csv   NaN\n",
      "2024-01-31  WHC.csv   NaN\n",
      "Name: ret-d1, Length: 544, dtype: float64>\n",
      "torch.Size([512, 33])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        ...,\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dataloader(df, batch_size=512, shuffle=False):\n",
    "    # Convert input features to float32 tensor (all columns except the last two)\n",
    "    X = torch.tensor(df.iloc[:, :-2].astype('float32').values)\n",
    "    # Convert labels (second-to-last column) to int64 tensor\n",
    "    y = torch.tensor(df.iloc[:, -2].astype('int64').values)\n",
    "    # Wrap tensors in a TensorDataset and return a DataLoader\n",
    "    dataset = TensorDataset(X, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "print(train_data[\"ret-d1\"].tail)\n",
    "# Create a DataLoader for training with shuffling\n",
    "dataloader = create_dataloader(train_data, shuffle=True)\n",
    "\n",
    "# Fetch one mini-batch from the DataLoader\n",
    "batch_X, batch_y = next(iter(dataloader))\n",
    "\n",
    "# Inspect the shapes of the input features and labels\n",
    "print(batch_X.shape)  # e.g., torch.Size([512, 33])\n",
    "print(batch_y.shape)  # e.g., torch.Size([512])\n",
    "\n",
    "# Initialize the model and run a forward pass on one batch\n",
    "model = FFNN()\n",
    "model(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV-StockTrade01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
